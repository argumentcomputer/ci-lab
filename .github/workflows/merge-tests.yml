# Run final tests only when attempting to merge, shown as skipped status checks beforehand
name: Merge group tests

on:
  pull_request:
    types: [opened, synchronize, reopened, ready_for_review]
    branches: [main]
  merge_group:

concurrency:
  group: ${{ github.workflow }}-${{ github.head_ref || github.run_id }}
  cancel-in-progress: true

jobs:
  # NOTE: Replica of lurk-rs merge-tests GPU benchmark, no GPU here and only benches a regular fibonacci function
  gpu-benchmark:
    # Test working run
    if: github.event_name != 'pull_request' || github.event.action == 'enqueued'
    name: Run fibonacci bench
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      # Install dependencies
      - uses: actions-rs/toolchain@v1
      - uses: Swatinem/rust-cache@v2
      - uses: taiki-e/install-action@v2
        with:
          tool: just@1.15
      - name: Install criterion
        run: |
          cargo install cargo-criterion
          cargo install criterion-table
      - name: Set env vars
        run: |
          # Set bench output format type
          echo "LURK_BENCH_OUTPUT=commit-comment" | tee -a $GITHUB_ENV
          # Get CPU model
          echo "CPU_MODEL=$(grep '^model name' /proc/cpuinfo | head -1 | awk -F ': ' '{ print $2 }')" | tee -a $GITHUB_ENV
      # Checkout base branch for comparative bench
      - uses: actions/checkout@v4
        with:
          ref: main
          path: main
      - name: Set base ref variable
        run: echo "BASE_REF=$(git rev-parse HEAD)" | tee -a $GITHUB_ENV
        working-directory: ${{ github.workspace }}/main
      - uses: actions/cache/restore@v3
        id: cache-bench-restore
        with:
          path: ${{ env.BASE_REF }}.json
          # Change this to $GPU_MODEL for lurk-rs
          key: gpu-bench-$CPU_MODEL-${{ env.BASE_REF }}
        working-directory: ${{ github.workspace }}
      - name: Check for cache hit
        if: steps.cache-bench-restore.outputs.cache-hit == 'true'
        run: echo "CACHE HIT"
      - name: Run GPU bench on base branch
        if: steps.cache-bench-restore.outputs.cache-hit != 'true'
        run: |
          just --justfile ../benches/justfile --dotenv-filename ../benches/bench.env bench fibonacci
          # Copy bench output to PR branch
          cp ${{ env.BASE_REF }}.json ..
        working-directory: ${{ github.workspace }}/main
      - name: Run GPU bench on PR branch
        run: just --justfile benches/justfile --dotenv-filename benches/bench.env bench fibonacci
        working-directory: ${{ github.workspace }}/benches
      - name: copy the benchmark template and prepare it with data
        run: |
          cp .github/tables.toml .
          # Get total RAM in GB
          TOTAL_RAM=$(grep MemTotal /proc/meminfo | awk '{$2=$2/(1024^2); print $2, "GB RAM";}')

          # Use conditionals to ensure that only non-empty variables are inserted
          [[ ! -z "${{ env.CPU_MODEL }}" ]] && sed -i "/^\"\"\"$/i ${{ env.CPU_MODEL }}" tables.toml
          [[ ! -z "$TOTAL_RAM" ]] && sed -i "/^\"\"\"$/i $TOTAL_RAM" tables.toml 
        working-directory: ${{ github.workspace }}
      # TODO: Fail on regression (e.g. `criterion-table` comparative output of `1.10+ slower`)
      # Create a `criterion-table` and write in commit comment
      - name: Run `criterion-table`
        run: cat ${{ env.BASE_REF }}.json ${{ github.sha }}.json | criterion-table > BENCHMARKS.md
      - name: Write bench on commit comment
        uses: peter-evans/commit-comment@v3
        with:
          body-path: BENCHMARKS.md
      # TODO: Only run if there is no failure due to regression
      - uses: actions/cache/save@v3
        id: cache-bench-save
        with:
          path: ${{ github.sha }}.json
          # Change this to $GPU_MODEL for lurk-rs
          key: gpu-bench-$CPU_MODEL-${{ github.sha }}
        working-directory: ${{ github.workspace }}
